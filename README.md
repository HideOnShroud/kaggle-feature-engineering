# Kaggle Feature Engineering

This repository contains a series of Kaggle Notebooks created while progressing through the Kaggle Feature Engineering
Learning course. These resources are designed to help deepen your understanding and application of feature engineering principles.

![Certificate](/Guga%20Natroshvili%20-%20Feature%20Engineering.png)

## Overview

Feature engineering involves creating and modifying features to enhance the performance of machine learning models. This repository includes various techniques and methods for effective feature engineering, including both foundational principles and advanced techniques.

## Table of Contents

1. [Mutual Information](#mutual-information)
2. [Creating Features](#creating-features)
3. [Clustering With K-Means](#clustering-with-k-means)
4. [Principal Component Analysis](#principal-component-analysis)
5. [Target Encoding](#target-encoding)

## Mutual Information

**File**: `exercise-mutual-information.ipynb`

Learn how to use mutual information to identify features with high potential. This notebook includes:
- Understanding mutual information and its significance
- Implementing mutual information to assess feature relevance
- Visualizing and interpreting mutual information results

## Creating Features

**File**: `exercise-creating-features.ipynb`

This notebook focuses on transforming and creating new features using Pandas. Key topics include:
- Feature transformation techniques with Pandas
- Creating new features from existing data
- Practical examples of feature creation for modeling

## Clustering With K-Means

**File**: `exercise-clustering-with-k-means.ipynb`

Explore how clustering can be used to untangle complex spatial relationships in your data. This notebook covers:
- Introduction to K-Means clustering
- Applying K-Means to create cluster labels
- Using cluster labels as features in machine learning models

## Principal Component Analysis

**File**: `exercise-principal-component-analysis.ipynb`

Discover how Principal Component Analysis (PCA) can be used to analyze and create new features based on variation in the data. This notebook includes:
- Basics of PCA and its application
- Implementing PCA to reduce dimensionality and extract features
- Interpreting PCA results and integrating them into your models

## Target Encoding

**File**: `exercise-target-encoding.ipynb`

Enhance categorical features with target encoding. This notebook includes:
- Explanation of target encoding and its benefits
- Implementing target encoding for categorical features
- Comparing target encoding with other encoding techniques

## Contributing

This repository is primarily for personal learning, but contributions and feedback are welcome. If you have suggestions or improvements, feel free to open an issue or create a pull request.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
